{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "melanoma classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYsGwEhDkW8ezx7R93MEew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisarahamedk/Kaggle_Notebooks/blob/master/melanoma_classification/efficient_net_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AStvxgZQNHsk",
        "colab_type": "text"
      },
      "source": [
        "## EfficientNet on TPU\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdVtqhiUMgfF",
        "colab_type": "text"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Imz3PGOYbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install -U efficientnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDsLy0fU6dHF",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNm_xBV16fxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import efficientnet.tfkeras as efn\n",
        "from kaggle_datasets import KaggleDatasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKe8yeNC6lOs",
        "colab_type": "text"
      },
      "source": [
        "### WandB Login"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80AfSsV8SCIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login f137298421da563b24639d1287dd3ce5da537814"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfxvEjlWSHZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wandb.init(project=\"kaggle-melanoma\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4Zh9fbDSItL",
        "colab_type": "text"
      },
      "source": [
        "## TPU Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZygZZ-6SJt6",
        "colab_type": "text"
      },
      "source": [
        "Detect hardware and return appropriate distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8WYRcWFSLj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # no parameter needed for TPU_NAME env variable is set. This is the case for Kaggle\n",
        "    print(\"Running on TPU: \", tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTynLUPfSM69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # default strategy with the available hw\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    \n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GEnNL_uSPo-",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae9ln7CFSQVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/train*\")\n",
        "test_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/test*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NPrafa4SUm9",
        "colab_type": "text"
      },
      "source": [
        "## tf.Dataset pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6cFxz2VSXhp",
        "colab_type": "text"
      },
      "source": [
        "Building the complete tfrecord -> model data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3eJY4D8SZvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = tf.data.TFRecordDataset(test_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eFR7C7yScNZ",
        "colab_type": "text"
      },
      "source": [
        "Checking the feature discription of the tfreceord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOS9CHH-Sdf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set\n",
        "for item in train_dataset.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(item.numpy())\n",
        "    print(example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FCjM0KBSfOI",
        "colab_type": "text"
      },
      "source": [
        "We have features: \"image\", \"image_name\" and \"target\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tMEk4NHShB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test set\n",
        "for item in test_dataset.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(item.numpy())\n",
        "    print(example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG_fpRXqSipe",
        "colab_type": "text"
      },
      "source": [
        "We have \"image\" and \"image_name\" for the test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM5nHK6OSkwp",
        "colab_type": "text"
      },
      "source": [
        "#### Feature description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXZUgDsvSmIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_feature_desc = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
        "}\n",
        "\n",
        "test_feature_desc = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqv4DL4-Snvq",
        "colab_type": "text"
      },
      "source": [
        "Using the above feature description,\n",
        "\n",
        "Lets load the dataset from the tfrecord files  \n",
        "1. Process it using the feature description.\n",
        "2. Decode each sample into an image.\n",
        "3. return image, target pairs\n",
        "4. Read from bottom to top"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o9z2-1wSyrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_image(image_data):\n",
        "    image_size = [1024, 1024]\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.reshape(image, [*image_size, 3])  # explicit size needed for TPU\n",
        "    image = tf.image.resize(image, [512, 512])\n",
        "    return image\n",
        "                           \n",
        "def parse_test_example(example):\n",
        "    \"\"\" function to parse each example read from the test tfrecord file\"\"\"\n",
        "    example = tf.io.parse_single_example(example, test_feature_desc)\n",
        "    image = decode_image(example[\"image\"])\n",
        "    image_name = example[\"image_name\"]\n",
        "    return image, image_name\n",
        "\n",
        "def parse_train_example(example):\n",
        "    \"\"\" function to parse each example read from the train tfrecord file\"\"\"\n",
        "    example = tf.io.parse_single_example(example, train_feature_desc)\n",
        "    image = decode_image(example[\"image\"])\n",
        "    label = tf.cast(example[\"target\"], tf.int32)\n",
        "    return image, label\n",
        "\n",
        "def load_dataset_from_tfrecord(filenames, is_training=True, ordered=False):\n",
        "    \n",
        "    # Since we are reading dataset from multiple files. and we dont care about the order.\n",
        "    # set deterministic reading to False.\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        "        \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
        "    dataset.with_options(ignore_order)\n",
        "    \n",
        "    # parse each example with feature description\n",
        "    dataset = dataset.map(parse_train_example if is_training else parse_test_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB6lIzKVS3xg",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation for the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsWk3V97S4SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn6l3jGFS6JI",
        "colab_type": "text"
      },
      "source": [
        "Finally, the datapipeline function that puts these all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdgGCNr_S7HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16 * strategy.num_replicas_in_sync\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset_from_tfrecord(train_files, is_training=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    # dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RJuwEndS810",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset_from_tfrecord(test_files, is_training=False, ordered=ordered)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjtmuLESS-ww",
        "colab_type": "text"
      },
      "source": [
        "Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVXLs2l_S_ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"*** Training set shapes *****\")\n",
        "for image, label in get_training_dataset().take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "    \n",
        "print(\"*** Training set labels: \", label.numpy())\n",
        "\n",
        "print(\"*** Test set shape ***\")\n",
        "for image, image_name in get_test_dataset().take(3):\n",
        "    print(image.numpy().shape, image_name.numpy().shape)\n",
        "print(\"*** Test set image_name: \", image_name.numpy().astype(\"U\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgD4k3YGTCTi",
        "colab_type": "text"
      },
      "source": [
        "### Model - Efficient Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwehCRd9TDDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    model = keras.Sequential([\n",
        "        efn.EfficientNetB3(\n",
        "            input_shape=[512, 512, 3],\n",
        "            weights=\"imagenet\",\n",
        "            include_top=False,\n",
        "        ),\n",
        "        keras.layers.GlobalAveragePooling2D(),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f7gwi5MTGcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z3J5UjOTHYq",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si-KANwNTIR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(get_training_dataset(), epochs=5, callbacks=[WandbCallback()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyYIc3sWTKjf",
        "colab_type": "text"
      },
      "source": [
        "### Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJm_IpKnTMT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = get_test_dataset(ordered=True)\n",
        "\n",
        "print(\"Computing predictions...\")\n",
        "test_image_ds = test_ds.map(lambda image, image_name: image)\n",
        "probs = model.predict(test_image_ds).flatten()\n",
        "print(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnrYmasTez1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ZCutEAVCBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Generating submission file\")\n",
        "num_test_images = count_data_items(test_files)\n",
        "test_image_names_ds = test_ds.map(lambda image, image_name: image_name).unbatch()\n",
        "\n",
        "test_image_names = next(iter(test_image_names_ds.batch(num_test_images))).numpy().astype('U') # all in one batch\n",
        "np.savetxt('submission.csv', np.rec.fromarrays([test_image_names, probs]), fmt=['%s', '%f'], delimiter=',', header='image_name,target', comments='')\n",
        "!head submission.csv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}