{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Training on TPU"},{"metadata":{},"cell_type":"markdown","source":"### Install packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install -U efficientnet","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nfrom functools import partial\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.backend as K\n\nimport pandas as pd\nimport numpy as np\nimport wandb\nfrom wandb.keras import WandbCallback\nfrom sklearn import model_selection\n\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WandB Login"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wandb login f137298421da563b24639d1287dd3ce5da537814","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"notes = \"one cycle learning rate, after find_lr\"\nwandb.init(project=\"kaggle-melanoma\", notes=notes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TPU Config"},{"metadata":{},"cell_type":"markdown","source":"Detect hardware and return appropriate distribution strategy"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # no parameter needed for TPU_NAME env variable is set. This is the case for Kaggle\n    print(\"Running on TPU: \", tpu.master())\nexcept ValueError:\n    tpu = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default strategy with the available hw\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Dataset from GCS for TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"siim-isic-melanoma-classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil ls $GCS_DS_PATH # list the GCS bucket","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/train*\")\ntest_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/test*\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_files), len(test_files)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train, Valid split"},{"metadata":{"trusted":true},"cell_type":"code","source":"LOCAL_DS_PATH = Path(\"/kaggle/input/siim-isic-melanoma-classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(LOCAL_DS_PATH / \"train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assign a fold id for each images using StratifiedKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"kfold\"] = -1\n\ny = train_df[\"target\"].values\n\nskf = model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X=train_df, y=y)):\n    train_df.loc[test_idx, \"kfold\"] = fold\n    \ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This way, when we run training with fold=1, images with column \"kfold=1\" will be kept in validation set, others in training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"kfold\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.Dataset pipeline "},{"metadata":{},"cell_type":"markdown","source":"Building the complete tfrecord -> model data pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\ntest_dataset = tf.data.TFRecordDataset(test_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Checking the feature discription of the tfreceord files"},{"metadata":{},"cell_type":"markdown","source":"We have features: \"image\", \"image_name\" and \"target\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# test set\nfor item in test_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(item.numpy())\n    print(example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have \"image\" and \"image_name\" for the test dataset"},{"metadata":{},"cell_type":"markdown","source":"#### Feature description\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature_desc = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"image_name\": tf.io.FixedLenFeature([], tf.string), # for filtering images belong to val set.\n    \"target\": tf.io.FixedLenFeature([], tf.int64),\n}\n\ntest_feature_desc = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"image_name\": tf.io.FixedLenFeature([], tf.string),\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the above feature description, \n* Lets load the dataset from the tfrecord files\n* Process it using the feature description.\n* Decode each sample into an image.\n* return image, target pairs  \n\n*Read from bottom to top*"},{"metadata":{"trusted":true},"cell_type":"code","source":"TPU_IMAGE_SIZE = 1024\nINPUT_IMAGE_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold = train_df[[\"image_name\", \"kfold\"]].set_index(\"image_name\").to_dict()\nfold = fold[\"kfold\"]\nfold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image_size = [TPU_IMAGE_SIZE, TPU_IMAGE_SIZE]\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*image_size, 3])  # explicit size needed for TPU\n    image = tf.image.resize(image, [INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE])\n    return image\n                           \ndef parse_test_example(example):\n    \"\"\" function to parse each example read from the test tfrecord file\"\"\"\n    example = tf.io.parse_single_example(example, test_feature_desc)\n    return example\n\ndef parse_train_example(example):\n    \"\"\" function to parse each example read from the train tfrecord file\"\"\"\n    example = tf.io.parse_single_example(example, train_feature_desc)\n    return example\n\ndef process_train_example(example):\n    image = decode_image(example[\"image\"])\n    label = tf.cast(example[\"target\"], tf.int32)\n    return image, label\n\ndef process_test_example(example):\n    image = decode_image(example[\"image\"])\n    image_name = example[\"image_name\"]\n    return image, image_name\n\ndef train_filter_fn(example):\n    # convert folds dict to tensorflow lookup table.\n    img_names = tf.constant(list(fold.keys()))\n    fold_idx = tf.constant(list(fold.values()))\n    folds_init = tf.lookup.KeyValueTensorInitializer(img_names, fold_idx)\n    folds_table = tf.lookup.StaticHashTable(folds_init, -1)\n    return folds_table.lookup(example[\"image_name\"]) != 1\n    \ndef valid_filter_fn(example):\n    # convert folds dict to tensorflow lookup table.\n    img_names = tf.constant(list(fold.keys()))\n    fold_idx = tf.constant(list(fold.values()))\n    folds_init = tf.lookup.KeyValueTensorInitializer(img_names, fold_idx)\n    folds_table = tf.lookup.StaticHashTable(folds_init, -1)\n    return folds_table.lookup(example[\"image_name\"]) == 1\n    \ndef load_dataset_from_tfrecord(filenames, ds_type=\"train\", ordered=False):\n    \n    # Since we are reading dataset from multiple files. and we dont care about the order.\n    # set deterministic reading to False.\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n    dataset.with_options(ignore_order)\n    \n    # parse each example with feature description\n    if ds_type in [\"train\", \"valid\"]:\n        dataset = dataset.map(parse_train_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        # filter  \n        # dataset = dataset.filter(train_filter_fn if ds_type==\"train\" else valid_filter_fn)\n        dataset = dataset.map(process_train_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    else:\n        dataset = dataset.map(parse_test_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        dataset = dataset.map(process_test_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    return dataset\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation for the image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def zoom(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Zoom augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n\n    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n    scales = list(np.arange(0.8, 1.0, 0.01))\n    boxes = np.zeros((len(scales), 4))\n\n    for i, scale in enumerate(scales):\n        x1 = y1 = 0.5 - (0.5 * scale)\n        x2 = y2 = 0.5 + (0.5 * scale)\n        boxes[i] = [x1, y1, x2, y2]\n\n    def random_crop(img):\n        # Create different crops for an image\n        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(32, 32))\n        # Return a random crop\n        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n\n\n    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n\n    # Only apply cropping 50% of the time\n    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):\n    # https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n    # try tfaddons augmentations\n    \n    # orientation\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    # color augmentation\n    image = tf.image.random_hue(image, 0.08)\n    image = tf.image.random_saturation(image, 0.6, 1.6)\n    image = tf.image.random_brightness(image, 0.05)\n    image = tf.image.random_contrast(image, 0.7, 1.3)\n    \n    # Random Zoom, This crops the image, need to be careful here, as the image shape changes\n    # image = zoom(image)\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, the datapipeline function that puts these all together"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16 * strategy.num_replicas_in_sync\ndef get_training_dataset(do_aug=True):\n    dataset = load_dataset_from_tfrecord(train_files[1:], ds_type=\"train\")\n    if do_aug:\n        dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    # dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_dataset(do_aug=True):\n    dataset = load_dataset_from_tfrecord([train_files[0]], ds_type=\"valid\")\n    if do_aug:\n        dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    # dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_dataset(ordered=False):\n    dataset = load_dataset_from_tfrecord(test_files, ds_type=\"test\", ordered=ordered)\n    dataset = dataset.batch(batch_size)\n    dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sanity check"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"*** Training set shapes *****\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n    \nprint(\"*** Training set labels: \", label.numpy())\n\nprint(\"*** Validation set shapes *****\")\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n    \nprint(\"*** Validation set labels: \", label.numpy())\n\n\nprint(\"*** Test set shape ***\")\nfor image, image_name in get_test_dataset().take(3):\n    print(image.numpy().shape, image_name.numpy().shape)\nprint(\"*** Test set image_name: \", image_name.numpy().astype(\"U\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model - Efficient Net "},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = keras.Sequential([\n        efn.EfficientNetB7(\n            input_shape=[INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3],\n            weights=\"imagenet\",\n            include_top=False,\n        ),\n        keras.layers.GlobalAveragePooling2D(),\n        keras.layers.Dense(1024, activation=\"relu\"),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(512, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(256, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dropout(0.1),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One cycle LR Scheduler"},{"metadata":{"trusted":true},"cell_type":"code","source":"class OneCycleLRScheduler(keras.callbacks.Callback):\n    def __init__(\n        self,\n        iterations,\n        max_rate,\n        start_rate=None,\n        last_iterations=None,\n        last_rate=None,\n    ):\n        self.iterations = iterations\n        self.max_rate = max_rate\n        self.start_rate = start_rate or max_rate / 10\n        self.last_iterations = last_iterations or self.iterations / 10 + 1\n        self.half_iteration = (iterations - self.last_iterations) // 2\n        self.last_rate = last_rate or self.start_rate / 1000\n        self.iteration = 0\n\n#         logging.info(f\"Total iterations: {self.iterations}\")\n#         logging.info(f\"Max rate: {self.max_rate}\")\n#         logging.info(f\"start_rate: {self.start_rate}\")\n#         logging.info(f\"last_iterations: {self.last_iterations}\")\n#         logging.info(f\"half_iteration: {self.half_iteration}\")\n#         logging.info(f\"last_rate: {self.last_rate}\")\n\n        self.lrs = []\n        self.losses = []\n\n    def _interpolate(self, iter1, iter2, rate1, rate2):\n        return (rate2 - rate1) * (iter2 - self.iteration) / (iter2 - iter1) + rate1\n\n    def on_batch_begin(self, batch, logs):  # pylint: disable=unused-argument\n        if self.iteration < self.half_iteration:\n            rate = self._interpolate(\n                0, self.half_iteration, self.start_rate, self.max_rate\n            )\n        elif self.iteration < 2 * self.half_iteration:\n            rate = self._interpolate(\n                self.half_iteration,\n                2 * self.half_iteration,\n                self.max_rate,\n                self.start_rate,\n            )\n        else:\n            rate = self._interpolate(\n                2 * self.half_iteration,\n                self.iterations,\n                self.start_rate,\n                self.last_rate,\n            )\n            rate = max(rate, self.last_rate)\n\n        self.lrs.append(rate)\n        self.iteration += 1\n        K.set_value(self.model.optimizer.lr, rate)\n\n    def on_batch_end(self, batch, logs):  # pylint: disable=unused-argument\n        self.losses.append(logs[\"loss\"])\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs[\"lr\"] = K.get_value(self.model.optimizer.lr)\n\n\ndef find_lr(model, dataset, n_batches, epochs=1, min_rate=1e-6, max_rate=1):\n    \"\"\"find a starting point LR for using as a max_rate for OneCycleLRScheduler\"\"\"\n    \n    class ExponentialLRScheduler(keras.callbacks.Callback):\n        def __init__(self, factor):\n            super().__init__()\n            self.factor = factor\n            self.losses = []\n            self.lrs = []\n\n        def on_batch_end(self, batch, logs):  # pylint: disable=unused-argument\n            self.lrs.append(K.get_value(self.model.optimizer.lr))\n            self.losses.append(logs[\"loss\"])\n            K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n            \n    init_weights = model.get_weights()  # backup\n    steps = n_batches * epochs\n    factor = np.exp(np.log(max_rate / min_rate) / steps)\n\n    init_lr = K.get_value(model.optimizer.lr)\n    K.set_value(model.optimizer.lr, min_rate)\n    exp_lr = ExponentialLRScheduler(factor)\n\n    history = model.fit(\n        dataset,\n        epochs=epochs,\n        # steps_per_epoch=dataset.n_train_batches,\n        callbacks=[exp_lr],\n    )\n\n    # restore\n    K.set_value(model.optimizer.lr, init_lr)\n    model.set_weights(init_weights)\n\n    return exp_lr.losses, exp_lr.lrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\", \n    loss=\"binary_crossentropy\", \n    # loss=tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1), # This is if noisy labels.\n    metrics=[\"accuracy\", keras.metrics.AUC()]\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"losses, lrs = find_lr(model, dataset=get_training_dataset(do_aug=False), n_batches=243)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = sns.lineplot(x=lrs, y=losses)\nax = p.axes \nax.set_ylim(0, 2)\nax.set_xlim(0, 3e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onecycle_cb = OneCycleLRScheduler(iterations=243 * 10, max_rate=3e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(get_training_dataset(), validation_data=get_validation_dataset(), epochs=10, callbacks=[WandbCallback(), onecycle_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint(\"Computing predictions...\")\ntest_image_ds = test_ds.map(lambda image, image_name: image)\nprobs = model.predict(test_image_ds).flatten()\nprint(probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Generating submission file\")\nnum_test_images = count_data_items(test_files)\ntest_image_names_ds = test_ds.map(lambda image, image_name: image_name).unbatch()\n\ntest_image_names = next(iter(test_image_names_ds.batch(num_test_images))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_image_names, probs]), fmt=['%s', '%f'], delimiter=',', header='image_name,target', comments='')\n!head submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}