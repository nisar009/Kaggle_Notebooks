{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Training on TPU"},{"metadata":{},"cell_type":"markdown","source":"### Install packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install -U efficientnet","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nfrom functools import partial\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport pandas as pd\nimport numpy as np\nimport wandb\nfrom wandb.keras import WandbCallback\nfrom sklearn import model_selection\n\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WandB Login"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wandb login f137298421da563b24639d1287dd3ce5da537814","execution_count":4,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"notes = \"1 out of 16 tfrec files used for validation set\"\nwandb.init(project=\"kaggle-melanoma\", notes=notes)","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/nisarahamedk/kaggle-melanoma\" target=\"_blank\">https://app.wandb.ai/nisarahamedk/kaggle-melanoma</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/nisarahamedk/kaggle-melanoma/runs/319xv0vh\" target=\"_blank\">https://app.wandb.ai/nisarahamedk/kaggle-melanoma/runs/319xv0vh</a><br/>\n            "},"metadata":{}},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.8.36 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","name":"stderr"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"W&B Run: https://app.wandb.ai/nisarahamedk/kaggle-melanoma/runs/319xv0vh"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## TPU Config"},{"metadata":{},"cell_type":"markdown","source":"Detect hardware and return appropriate distribution strategy"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # no parameter needed for TPU_NAME env variable is set. This is the case for Kaggle\n    print(\"Running on TPU: \", tpu.master())\nexcept ValueError:\n    tpu = None","execution_count":6,"outputs":[{"output_type":"stream","text":"Running on TPU:  grpc://10.0.0.2:8470\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default strategy with the available hw\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":7,"outputs":[{"output_type":"stream","text":"REPLICAS:  8\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Dataset from GCS for TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"siim-isic-melanoma-classification\")","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"'gs://kds-0b2c68d2b2fa4692fcffc1029c606b32dd6a88de8d6da08fcd30d0c4'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil ls $GCS_DS_PATH # list the GCS bucket","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/train*\")\ntest_files = tf.io.gfile.glob(GCS_DS_PATH + \"/tfrecords/test*\")","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_files), len(test_files)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(16, 16)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Train, Valid split"},{"metadata":{"trusted":true},"cell_type":"code","source":"LOCAL_DS_PATH = Path(\"/kaggle/input/siim-isic-melanoma-classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(LOCAL_DS_PATH / \"train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assign a fold id for each images using StratifiedKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"kfold\"] = -1\n\ny = train_df[\"target\"].values\n\nskf = model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X=train_df, y=y)):\n    train_df.loc[test_idx, \"kfold\"] = fold\n    \ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This way, when we run training with fold=1, images with column \"kfold=1\" will be kept in validation set, others in training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"kfold\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.Dataset pipeline "},{"metadata":{},"cell_type":"markdown","source":"Building the complete tfrecord -> model data pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.TFRecordDataset(train_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\ntest_dataset = tf.data.TFRecordDataset(test_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Checking the feature discription of the tfreceord files"},{"metadata":{},"cell_type":"markdown","source":"We have features: \"image\", \"image_name\" and \"target\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# test set\nfor item in test_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(item.numpy())\n    print(example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have \"image\" and \"image_name\" for the test dataset"},{"metadata":{},"cell_type":"markdown","source":"#### Feature description\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature_desc = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"image_name\": tf.io.FixedLenFeature([], tf.string), # for filtering images belong to val set.\n    \"target\": tf.io.FixedLenFeature([], tf.int64),\n}\n\ntest_feature_desc = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"image_name\": tf.io.FixedLenFeature([], tf.string),\n}","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the above feature description, \n* Lets load the dataset from the tfrecord files\n* Process it using the feature description.\n* Decode each sample into an image.\n* return image, target pairs  \n\n*Read from bottom to top*"},{"metadata":{"trusted":true},"cell_type":"code","source":"TPU_IMAGE_SIZE = 1024\nINPUT_IMAGE_SIZE = 512","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold = train_df[[\"image_name\", \"kfold\"]].set_index(\"image_name\").to_dict()\nfold = fold[\"kfold\"]\nfold","execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-8d34e555d28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kfold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kfold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image_size = [TPU_IMAGE_SIZE, TPU_IMAGE_SIZE]\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*image_size, 3])  # explicit size needed for TPU\n    image = tf.image.resize(image, [INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE])\n    return image\n                           \ndef parse_test_example(example):\n    \"\"\" function to parse each example read from the test tfrecord file\"\"\"\n    example = tf.io.parse_single_example(example, test_feature_desc)\n    return example\n\ndef parse_train_example(example):\n    \"\"\" function to parse each example read from the train tfrecord file\"\"\"\n    example = tf.io.parse_single_example(example, train_feature_desc)\n    return example\n\ndef process_train_example(example):\n    image = decode_image(example[\"image\"])\n    label = tf.cast(example[\"target\"], tf.int32)\n    return image, label\n\ndef process_test_example(example):\n    image = decode_image(example[\"image\"])\n    image_name = example[\"image_name\"]\n    return image, image_name\n\ndef train_filter_fn(example):\n    # convert folds dict to tensorflow lookup table.\n    img_names = tf.constant(list(fold.keys()))\n    fold_idx = tf.constant(list(fold.values()))\n    folds_init = tf.lookup.KeyValueTensorInitializer(img_names, fold_idx)\n    folds_table = tf.lookup.StaticHashTable(folds_init, -1)\n    return folds_table.lookup(example[\"image_name\"]) != 1\n    \ndef valid_filter_fn(example):\n    # convert folds dict to tensorflow lookup table.\n    img_names = tf.constant(list(fold.keys()))\n    fold_idx = tf.constant(list(fold.values()))\n    folds_init = tf.lookup.KeyValueTensorInitializer(img_names, fold_idx)\n    folds_table = tf.lookup.StaticHashTable(folds_init, -1)\n    return folds_table.lookup(example[\"image_name\"]) == 1\n    \ndef load_dataset_from_tfrecord(filenames, ds_type=\"train\", ordered=False):\n    \n    # Since we are reading dataset from multiple files. and we dont care about the order.\n    # set deterministic reading to False.\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n    dataset.with_options(ignore_order)\n    \n    # parse each example with feature description\n    if ds_type in [\"train\", \"valid\"]:\n        dataset = dataset.map(parse_train_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        # filter  \n        # dataset = dataset.filter(train_filter_fn if ds_type==\"train\" else valid_filter_fn)\n        dataset = dataset.map(process_train_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    else:\n        dataset = dataset.map(parse_test_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        dataset = dataset.map(process_test_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    return dataset\n    ","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation for the image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):\n    # https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n    image = tf.image.random_flip_left_right(image)\n    return image, label","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, the datapipeline function that puts these all together"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16 * strategy.num_replicas_in_sync\ndef get_training_dataset():\n    dataset = load_dataset_from_tfrecord(train_files[1:], ds_type=\"train\")\n    dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    # dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    \n    return dataset","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_dataset():\n    dataset = load_dataset_from_tfrecord([train_files[0]], ds_type=\"valid\")\n    dataset = dataset.map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    # dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    \n    return dataset","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_dataset(ordered=False):\n    dataset = load_dataset_from_tfrecord(test_files, ds_type=\"test\", ordered=ordered)\n    dataset = dataset.batch(batch_size)\n    dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sanity check"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"*** Training set shapes *****\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n    \nprint(\"*** Training set labels: \", label.numpy())\n\nprint(\"*** Validation set shapes *****\")\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\n    \nprint(\"*** Validation set labels: \", label.numpy())\n\n\nprint(\"*** Test set shape ***\")\nfor image, image_name in get_test_dataset().take(3):\n    print(image.numpy().shape, image_name.numpy().shape)\nprint(\"*** Test set image_name: \", image_name.numpy().astype(\"U\"))","execution_count":31,"outputs":[{"output_type":"stream","text":"*** Training set shapes *****\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n*** Training set labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n*** Validation set shapes *****\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n*** Validation set labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n*** Test set shape ***\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n(128, 512, 512, 3) (128,)\n*** Test set image_name:  ['ISIC_3009035' 'ISIC_1579773' 'ISIC_6082685' 'ISIC_1263999'\n 'ISIC_4348477' 'ISIC_3740111' 'ISIC_1071664' 'ISIC_1560363'\n 'ISIC_5223297' 'ISIC_7851934' 'ISIC_7889564' 'ISIC_4556233'\n 'ISIC_4384149' 'ISIC_1673959' 'ISIC_4059973' 'ISIC_4624150'\n 'ISIC_5420567' 'ISIC_1921353' 'ISIC_3164346' 'ISIC_9655502'\n 'ISIC_8469607' 'ISIC_2598603' 'ISIC_4263498' 'ISIC_7894734'\n 'ISIC_7206758' 'ISIC_5966072' 'ISIC_3609057' 'ISIC_8941788'\n 'ISIC_5787712' 'ISIC_7743612' 'ISIC_5670844' 'ISIC_0142066'\n 'ISIC_9308692' 'ISIC_9782532' 'ISIC_8179996' 'ISIC_0082004'\n 'ISIC_4244166' 'ISIC_0809747' 'ISIC_8472353' 'ISIC_6759399'\n 'ISIC_5294076' 'ISIC_4778220' 'ISIC_0473489' 'ISIC_3379782'\n 'ISIC_7027005' 'ISIC_8188409' 'ISIC_0620581' 'ISIC_5731724'\n 'ISIC_0989319' 'ISIC_8437178' 'ISIC_2331559' 'ISIC_1675841'\n 'ISIC_0756977' 'ISIC_9825062' 'ISIC_7597450' 'ISIC_1494327'\n 'ISIC_2695905' 'ISIC_2361309' 'ISIC_2402484' 'ISIC_6885654'\n 'ISIC_9589360' 'ISIC_4808532' 'ISIC_3614842' 'ISIC_3937767'\n 'ISIC_0169575' 'ISIC_9497933' 'ISIC_0395885' 'ISIC_8678730'\n 'ISIC_6900567' 'ISIC_0620316' 'ISIC_7904453' 'ISIC_3414807'\n 'ISIC_3514405' 'ISIC_1354933' 'ISIC_2680409' 'ISIC_1373939'\n 'ISIC_7785749' 'ISIC_1889661' 'ISIC_5003515' 'ISIC_0433895'\n 'ISIC_5285042' 'ISIC_9253871' 'ISIC_7240170' 'ISIC_0685067'\n 'ISIC_1725083' 'ISIC_6677512' 'ISIC_1450044' 'ISIC_8664024'\n 'ISIC_7411679' 'ISIC_3096116' 'ISIC_8443990' 'ISIC_7114023'\n 'ISIC_6426773' 'ISIC_5944731' 'ISIC_6185319' 'ISIC_1904819'\n 'ISIC_9853298' 'ISIC_7671624' 'ISIC_3188729' 'ISIC_7014635'\n 'ISIC_9448856' 'ISIC_7736823' 'ISIC_0313675' 'ISIC_3086004'\n 'ISIC_7414621' 'ISIC_6438534' 'ISIC_2922450' 'ISIC_8122278'\n 'ISIC_1100351' 'ISIC_6244226' 'ISIC_9875614' 'ISIC_6755755'\n 'ISIC_6903816' 'ISIC_0372971' 'ISIC_4031425' 'ISIC_7654912'\n 'ISIC_1233031' 'ISIC_2722983' 'ISIC_2543386' 'ISIC_6683074'\n 'ISIC_9093252' 'ISIC_7753184' 'ISIC_2028661' 'ISIC_7106250'\n 'ISIC_4498984' 'ISIC_9737914' 'ISIC_2455226' 'ISIC_7468924']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Model - Efficient Net "},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = keras.Sequential([\n        efn.EfficientNetB7(\n            input_shape=[INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3],\n            weights=\"imagenet\",\n            include_top=False,\n        ),\n        keras.layers.GlobalAveragePooling2D(),\n        keras.layers.Dense(1024, activation=\"relu\"),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(512, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(256, activation=\"relu\"),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dropout(0.1),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\", \n    # loss=\"binary_crossentropy\", \n    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1), \n    metrics=[\"accuracy\", keras.metrics.AUC()]\n)\n\nmodel.summary()","execution_count":33,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b7 (Model)      (None, 16, 16, 2560)      64097680  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2560)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1024)              2622464   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 67,409,297\nTrainable params: 67,098,577\nNon-trainable params: 310,720\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(get_training_dataset(), validation_data=get_validation_dataset(), epochs=10, callbacks=[WandbCallback()])","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint(\"Computing predictions...\")\ntest_image_ds = test_ds.map(lambda image, image_name: image)\nprobs = model.predict(test_image_ds).flatten()\nprint(probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Generating submission file\")\nnum_test_images = count_data_items(test_files)\ntest_image_names_ds = test_ds.map(lambda image, image_name: image_name).unbatch()\n\ntest_image_names = next(iter(test_image_names_ds.batch(num_test_images))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_image_names, probs]), fmt=['%s', '%f'], delimiter=',', header='image_name,target', comments='')\n!head submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}